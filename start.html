const elevenApiKey = 'YOUR_ELEVENLABS_API_KEY'; // üîê Replace this with your real ElevenLabs API key

const voiceSelect = document.getElementById('voiceSelect');
const generateButton = document.getElementById('generateBtn');
const audioPlayer = document.getElementById('audioPlayer');
const outputText = document.getElementById('outputText');

// üîÅ Load available ElevenLabs voices dynamically
async function loadVoices() {
  voiceSelect.innerHTML = '<option disabled selected>Loading voices...</option>';
  try {
    const response = await fetch('https://api.elevenlabs.io/v1/voices', {
      headers: { 'xi-api-key': elevenApiKey }
    });

    if (!response.ok) throw new Error(`Failed to fetch voices: ${response.statusText}`);

    const data = await response.json();
    voiceSelect.innerHTML = ''; // Clear loading option

    data.voices.forEach(voice => {
      const option = document.createElement('option');
      option.value = voice.voice_id;
      option.textContent = voice.name;
      voiceSelect.appendChild(option);
    });
  } catch (err) {
    console.error('Voice loading error:', err);
    voiceSelect.innerHTML = '<option disabled selected>Error loading voices</option>';
  }
}

// üß† Generate story and convert it to voice
async function generateAudio() {
  const language = document.getElementById('languageSelect').value;
  const level = document.getElementById('levelSelect').value;
  const voiceId = voiceSelect.value;

  if (!voiceId) {
    outputText.textContent = '‚ö†Ô∏è Please select a voice.';
    return;
  }

  const prompt = `Explain what AI is to a ${level} in ${language} using friendly storytelling.`;

  try {
    outputText.textContent = 'üß† Generating your story...';

    // Step 1: Call backend to get OpenAI-generated story
    const gptResponse = await fetch('/api/generate-story', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt })
    });

    if (!gptResponse.ok) {
      throw new Error(`OpenAI story generation failed: ${gptResponse.statusText}`);
    }

    const gptData = await gptResponse.json();
    const story = gptData.text;

    if (!story || typeof story !== 'string') {
      outputText.textContent = '‚ùå No story returned.';
      return;
    }

    outputText.textContent = story;

    // Step 2: Convert text to audio via ElevenLabs
    const ttsResponse = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
      method: 'POST',
      headers: {
        'xi-api-key': elevenApiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        text: story,
        model_id: 'eleven_monolingual_v1',
        voice_settings: {
          stability: 0.4,
          similarity_boost: 0.7
        }
      })
    });

    if (!ttsResponse.ok) {
      const errorDetails = await ttsResponse.json();
      console.error('ElevenLabs TTS error:', errorDetails);
      outputText.textContent = '‚ùå Voice generation failed.';
      return;
    }

    const audioBlob = await ttsResponse.blob();
    const audioUrl = URL.createObjectURL(audioBlob);
    audioPlayer.src = audioUrl;
    audioPlayer.play();
  } catch (err) {
    console.error('‚ùå Error during generation:', err);
    outputText.textContent = 'Something went wrong. Please try again.';
  }
}

// üöÄ Initialize on page load
window.onload = () => {
  loadVoices();
  generateButton.addEventListener('click', generateAudio);
};
